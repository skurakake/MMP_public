{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1nniIuEvcqBmJYg5OXQkLl4xTEcmeIR03",
      "authorship_tag": "ABX9TyNKrHKwQQkejbJkTIj7mDc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skurakake/MMP_public/blob/main/Resnet34_C100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "metadata": {
        "id": "D83K_cKh9itR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "vmmEnahH0Fgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = '/content/drive/MyDrive/Colab Notebooks/temp'\n",
        "\n",
        "if not os.path.exists(MODEL_DIR):  # ディレクトリが存在しない場合、作成する。\n",
        "    os.makedirs(MODEL_DIR)\n"
      ],
      "metadata": {
        "id": "vOpf5Hnqm8ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn7w4A27ScgU"
      },
      "outputs": [],
      "source": [
        "# cifar100 を使う\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "\n",
        "CIFAR100_LABELS_LIST = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "    'worm'\n",
        "]\n",
        "\n",
        "num_category = 100 # クラス数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrhds3dGUucF"
      },
      "outputs": [],
      "source": [
        "# ダウンロードしたデータの一部をランダムに表示\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('the number of train samples:', x_train.shape[0] )\n",
        "print('the number of test samples:', x_test.shape[0] )\n",
        "print(type(x_train[0]))\n",
        "\n",
        "print(x_train.shape, t_train.shape)\n",
        "print(x_test.shape, t_test.shape)\n",
        "print(type(x_test))\n",
        "print(type(t_test[0]))\n",
        "\n",
        "\n",
        "num_image = 20 # 表示数\n",
        "rand_idx = np.random.randint(0, len(x_train), num_image)\n",
        "plt.figure(figsize=(5, 5)) # 表示領域のサイズ\n",
        "# plt figure set to 5inch x 5inch(500pixel x 500 pixel).\n",
        "\n",
        "labels = CIFAR100_LABELS_LIST\n",
        "for i in range(num_image):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(x_train[rand_idx[i]])\n",
        "    plt.title(labels[t_train[rand_idx[i]][0]])\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)\n",
        "\n",
        "plt.show() # 実行されたとき始めてウィンドウが立ち上がり、そのウィンドウに図が表示される\n",
        "# colab では plt.show() がなくても、環境が自動でウィンドウをオープンしてくれるが、\n",
        "# コマンドラインとかでは、これが必要"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training data\", len(x_train))\n",
        "print(\"Number of test data\", len(x_test))\n",
        "print(\"Number of label data for training\", len(t_train))\n",
        "print(\"Number of label data for test\", len(t_test))"
      ],
      "metadata": {
        "id": "VkAUBOvFd8eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_N =x_train /255\n",
        "x_test_N = x_test /255"
      ],
      "metadata": {
        "id": "gpa7VeBpLue-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定\n",
        "batch_size = 32 # ミニバッチサイズ\n",
        "epochs = 100 # エポック数\n",
        "num_class = 100 # クラス数\n",
        "\n",
        "# 正解データを one-hot 表現へ変換\n",
        "t_train_n = tf.keras.utils.to_categorical(t_train, num_class)\n",
        "t_test_n = tf.keras.utils.to_categorical(t_test, num_class)\n",
        "print(\"正解データ（学習）：\", t_train_n[5])\n",
        "print(\"正解データ（テスト）：\", t_test_n[22])"
      ],
      "metadata": {
        "id": "WtQQkefP64Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルの構築\n",
        "Functional API を使う。\n",
        "model = Model(inputs=input_tensor, outputs=outputs)　でモデルを定義する。"
      ],
      "metadata": {
        "id": "YFax4DRW8oBT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77461ba7"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAvgPool2D, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Resizing, Rescaling\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#  using Functional API\n",
        "def Residual_block1(input_tensor, c1, c2):\n",
        "    # Path 1 is a single 1 x 1 convolutional layer\n",
        "    p1_1 = Conv2D(c1[0], c1[1], padding='same')(input_tensor)\n",
        "    p1_2 = BatchNormalization()(p1_1)\n",
        "    p1_3 = Activation('relu')(p1_2)\n",
        "    p1_4 = Conv2D(c2[0], c2[1], padding='same')(p1_3)\n",
        "    p1_5 = BatchNormalization()(p1_4)\n",
        "    p1_6 = Conv2D(64, 1, padding='same')(p1_5)\n",
        "    p1_7 = p1_6 + input_tensor\n",
        "    p1_8 = Activation('relu')(p1_7)\n",
        "\n",
        "    return p1_8\n",
        "\n",
        "\n",
        "# Define the blocks using the Functional API\n",
        "def b1(input_tensor):\n",
        "    x = Resizing(224,224)(input_tensor)\n",
        "    x = Conv2D(64, 7, strides=2, padding='same', activation='relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def b2(input_tensor):\n",
        "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(input_tensor)\n",
        "    x = Residual_block1(x, (64,3),(64,3))\n",
        "    x = Residual_block1(x, (64,3),(64,3))\n",
        "    x = Residual_block1(x, (64,3),(64,3))\n",
        "    return x\n",
        "\n",
        "def b3(input_tensor):\n",
        "    x = Residual_block1(input_tensor, (128,3), (128,3))\n",
        "    x = Residual_block1(x, (128,3), (128,3))\n",
        "    x = Residual_block1(x, (128,3), (128,3))\n",
        "    x = Residual_block1(x, (128,3), (128,3))\n",
        "    return x\n",
        "\n",
        "def b4(input_tensor):\n",
        "    x = Residual_block1(input_tensor, (256, 3),(256, 3))\n",
        "    x = Residual_block1(x, (256, 3),(256, 3))\n",
        "    x = Residual_block1(x, (256, 3),(256, 3))\n",
        "    x = Residual_block1(x, (256, 3),(256, 3))\n",
        "    x = Residual_block1(x, (256, 3),(256, 3))\n",
        "    x = Residual_block1(x, (256, 3),(256, 3))\n",
        "\n",
        "    return x\n",
        "\n",
        "def b5(input_tensor):\n",
        "    x = Residual_block1(input_tensor, (512, 3),(512, 3))\n",
        "    x = Residual_block1(x, (512, 3),(512, 3))\n",
        "    x = Residual_block1(x, (512, 3),(512, 3))\n",
        "    return x\n",
        "\n",
        "# Build the complete model\n",
        "input_tensor = Input(shape=x_train.shape[1:])\n",
        "x = b1(input_tensor)\n",
        "x = b2(x)\n",
        "x = b3(x)\n",
        "x = b4(x)\n",
        "x = b5(x)\n",
        "x = GlobalAvgPool2D()(x)\n",
        "x = Flatten()(x)\n",
        "x =Dropout(0.5)(x)\n",
        "outputs = Dense(1000)(x)\n",
        "x =Dropout(0.5)(x)\n",
        "outputs = Dense(num_class, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存先のパスを設定。Googleドライブ内のパスを指定。\n",
        "# checkpoint_filepath = os.path.join(MODEL_DIR, '/my_best_model.keras')\n",
        "checkpoint_filepath = os.path.join(MODEL_DIR, 'my_Resnet1.keras')\n",
        "\n",
        "# ModelCheckpoint コールバックを定義します\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',       # 監視する指標 (例: 検証精度)\n",
        "    save_best_only=True,         # 最も性能の良いモデルのみを保存する\n",
        "    save_weights_only=False,     # モデルのアーキテクチャとトレーニング設定も保存する\n",
        "    mode='max',                  # 監視指標の最大値が最良であることを指定 ('max' or 'min')\n",
        "    verbose=1                    # 保存時にメッセージを表示\n",
        ")"
      ],
      "metadata": {
        "id": "A9J2Mz-bXzsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの読み込み\n",
        "model.load_weights(os.path.join(MODEL_DIR, \"my_Resnet1.keras\"))  # のモデルを指定\n"
      ],
      "metadata": {
        "id": "F7aohHJwrgF0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルを訓練する"
      ],
      "metadata": {
        "id": "Zya5voduRs-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#x_train_N =x_train /255\n",
        "#x_test_N = x_test /255\n",
        "\n",
        "history = model.fit(x_train, t_train_n, batch_size=batch_size,\n",
        "                    epochs=epochs, validation_data=(x_test, t_test_n),\n",
        "                    callbacks=[model_checkpoint_callback] # ここでコールバックを指定\n",
        "                    )"
      ],
      "metadata": {
        "id": "ZzjFnWN3Rwml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の経過をグラフで表示\n",
        "import matplotlib.pyplot as plt\n",
        "train_loss = history.history['loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "validation_loss = history.history['val_loss']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(np.arange(len(train_loss)), train_loss, label='training_loss')\n",
        "plt.plot(np.arange(len(validation_loss)), validation_loss, label='validation_loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(train_accuracy)), train_accuracy, label='training_accuracy')\n",
        "plt.plot(np.arange(len(validation_accuracy)), validation_accuracy, label='validation_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FbneqHRDmSCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}